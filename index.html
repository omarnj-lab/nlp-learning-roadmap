<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>NLP Learning Journey - By Eng. Omer Nacar</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Inter', -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
            background: #000;
            overflow: hidden;
            color: #fff;
            position: relative;
            min-height: 100vh;
        }

        /* Animated background */
        body::before {
            content: '';
            position: fixed;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            background: 
                radial-gradient(circle at 20% 50%, rgba(120, 119, 198, 0.3) 0%, transparent 50%),
                radial-gradient(circle at 80% 80%, rgba(255, 119, 198, 0.3) 0%, transparent 50%),
                radial-gradient(circle at 40% 20%, rgba(119, 198, 255, 0.3) 0%, transparent 50%);
            animation: backgroundShift 20s ease-in-out infinite;
            z-index: -1;
        }

        @keyframes backgroundShift {
            0%, 100% { transform: scale(1) rotate(0deg); }
            33% { transform: scale(1.1) rotate(120deg); }
            66% { transform: scale(0.9) rotate(240deg); }
        }

        .header {
            position: fixed;
            top: 0;
            left: 0;
            right: 0;
            background: rgba(0, 0, 0, 0.9);
            backdrop-filter: blur(20px);
            padding: 20px 40px;
            z-index: 1000;
            border-bottom: 1px solid rgba(255, 255, 255, 0.1);
        }

        .header-content {
            max-width: 1400px;
            margin: 0 auto;
            display: flex;
            justify-content: space-between;
            align-items: center;
        }

        .title-section h1 {
            font-size: 2em;
            font-weight: 700;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
            margin-bottom: 5px;
        }

        .subtitle {
            color: #888;
            font-size: 0.9em;
        }

        .author {
            color: #667eea;
            font-weight: 600;
        }

        .progress-section {
            display: flex;
            align-items: center;
            gap: 20px;
        }

        .progress-bar {
            width: 200px;
            height: 6px;
            background: rgba(255, 255, 255, 0.1);
            border-radius: 3px;
            overflow: hidden;
        }

        .progress-fill {
            height: 100%;
            background: linear-gradient(90deg, #667eea 0%, #764ba2 100%);
            width: 0%;
            transition: width 0.5s cubic-bezier(0.4, 0, 0.2, 1);
        }

        .progress-text {
            color: #888;
            font-size: 0.9em;
            min-width: 120px;
            text-align: right;
        }

        .main-container {
            position: relative;
            padding-top: 100px;
            min-height: 100vh;
            display: flex;
            align-items: center;
            justify-content: center;
        }

        /* Home View with NLP Circle */
        .home-view {
            display: flex;
            align-items: center;
            justify-content: center;
            width: 100%;
            height: calc(100vh - 100px);
            transition: opacity 0.5s ease;
        }

        .home-view.hidden {
            display: none;
        }

        .nlp-main-node {
            width: 250px;
            height: 250px;
            background: radial-gradient(circle, rgba(102, 126, 234, 0.2) 0%, transparent 70%);
            border-radius: 50%;
            display: flex;
            align-items: center;
            justify-content: center;
            position: relative;
            cursor: pointer;
            transition: transform 0.3s ease;
        }

        .nlp-main-node::before {
            content: '';
            position: absolute;
            width: 100%;
            height: 100%;
            border-radius: 50%;
            border: 3px solid #667eea;
            animation: pulse 2s ease-in-out infinite;
        }

        .nlp-main-node:hover {
            transform: scale(1.05);
        }

        .nlp-main-node:hover::before {
            animation-duration: 0.5s;
        }

        @keyframes pulse {
            0%, 100% { transform: scale(1); opacity: 1; }
            50% { transform: scale(1.1); opacity: 0.5; }
        }

        .nlp-main-node h2 {
            font-size: 4em;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
            user-select: none;
        }

        /* Topics View */
        .topics-view {
            display: none;
            align-items: center;
            justify-content: center;
            width: 100%;
            height: calc(100vh - 100px);
            gap: 80px;
            padding: 40px;
            position: relative;
        }

        .topics-view.active {
            display: flex;
        }

        .topic-circle {
            width: 200px;
            height: 200px;
            background: rgba(255, 255, 255, 0.05);
            backdrop-filter: blur(10px);
            border: 2px solid rgba(255, 255, 255, 0.2);
            border-radius: 50%;
            display: flex;
            align-items: center;
            justify-content: center;
            cursor: pointer;
            transition: all 0.3s cubic-bezier(0.4, 0, 0.2, 1);
            position: relative;
            overflow: hidden;
            animation: fadeInScale 0.5s ease-out;
        }

        @keyframes fadeInScale {
            from {
                opacity: 0;
                transform: scale(0.8);
            }
            to {
                opacity: 1;
                transform: scale(1);
            }
        }

        .topic-circle:nth-child(1) { animation-delay: 0.1s; }
        .topic-circle:nth-child(2) { animation-delay: 0.2s; }
        .topic-circle:nth-child(3) { animation-delay: 0.3s; }

        .topic-circle::before {
            content: '';
            position: absolute;
            top: -50%;
            left: -50%;
            width: 200%;
            height: 200%;
            background: radial-gradient(circle, rgba(255, 255, 255, 0.1) 0%, transparent 70%);
            transform: rotate(0deg);
            transition: transform 0.5s ease;
        }

        .topic-circle:hover::before {
            transform: rotate(180deg);
        }

        .topic-circle:hover {
            transform: translateY(-10px) scale(1.05);
            border-color: #667eea;
            box-shadow: 0 20px 40px rgba(102, 126, 234, 0.4);
        }

        .topic-circle h3 {
            font-size: 1.3em;
            text-align: center;
            position: relative;
            z-index: 1;
            user-select: none;
        }

        /* Roadmap View */
        .roadmap-view {
            display: none;
            width: 100%;
            height: calc(100vh - 100px);
            padding: 40px;
            overflow-x: auto;
            overflow-y: hidden;
        }

        .roadmap-view.active {
            display: block;
        }

        .roadmap-header {
            display: flex;
            align-items: center;
            gap: 20px;
            margin-bottom: 40px;
        }

        .back-button {
            width: 50px;
            height: 50px;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            backdrop-filter: blur(10px);
            border: 2px solid rgba(255, 255, 255, 0.3);
            border-radius: 50%;
            display: flex;
            align-items: center;
            justify-content: center;
            cursor: pointer;
            transition: all 0.3s ease;
            font-size: 1.8em;
            color: #fff;
            font-weight: bold;
            box-shadow: 0 4px 15px rgba(102, 126, 234, 0.4);
        }

        .back-button:hover {
            background: linear-gradient(135deg, #764ba2 0%, #667eea 100%);
            transform: translateX(-5px) scale(1.1);
            box-shadow: 0 6px 25px rgba(102, 126, 234, 0.6);
        }

        .roadmap-title {
            font-size: 2.5em;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
        }

        .methods-container {
            display: flex;
            gap: 40px;
            align-items: center;
            padding-bottom: 40px;
        }

        .method-node {
            background: rgba(255, 255, 255, 0.03);
            backdrop-filter: blur(10px);
            border: 1px solid rgba(255, 255, 255, 0.1);
            border-radius: 20px;
            padding: 25px;
            min-width: 280px;
            cursor: pointer;
            transition: all 0.3s cubic-bezier(0.4, 0, 0.2, 1);
            position: relative;
            overflow: hidden;
            animation: slideIn 0.5s ease-out;
        }

        @keyframes slideIn {
            from {
                opacity: 0;
                transform: translateX(30px);
            }
            to {
                opacity: 1;
                transform: translateX(0);
            }
        }

        .method-node::before {
            content: '';
            position: absolute;
            top: -2px;
            left: -2px;
            right: -2px;
            bottom: -2px;
            background: linear-gradient(45deg, #667eea, #764ba2, #667eea);
            border-radius: 20px;
            opacity: 0;
            z-index: -1;
            transition: opacity 0.3s ease;
        }

        .method-node:hover::before {
            opacity: 1;
            animation: borderRotate 3s linear infinite;
        }

        @keyframes borderRotate {
            0% { transform: rotate(0deg); }
            100% { transform: rotate(360deg); }
        }

        .method-node:hover {
            transform: translateY(-5px) scale(1.02);
            background: rgba(255, 255, 255, 0.08);
            box-shadow: 0 20px 40px rgba(102, 126, 234, 0.3);
        }

        .method-node.visited {
            background: rgba(102, 126, 234, 0.1);
            border-color: rgba(102, 126, 234, 0.5);
        }

        .method-title {
            font-size: 1.2em;
            font-weight: 600;
            margin-bottom: 10px;
            color: #fff;
        }

        .method-desc {
            font-size: 0.9em;
            color: #aaa;
            line-height: 1.5;
            margin-bottom: 15px;
        }

        .method-problems {
            font-size: 0.85em;
            color: #ff6b6b;
            display: flex;
            align-items: center;
            gap: 5px;
            cursor: pointer;
        }

        .arrow-connector {
            color: #667eea;
            font-size: 2.5em;
            margin: 0 10px;
            animation: slideRight 2s ease-in-out infinite;
        }

        @keyframes slideRight {
            0%, 100% { transform: translateX(0); }
            50% { transform: translateX(10px); }
        }

        .modal {
            display: none;
            position: fixed;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            background: rgba(0, 0, 0, 0.95);
            backdrop-filter: blur(10px);
            z-index: 2000;
            align-items: center;
            justify-content: center;
            padding: 20px;
        }

        .modal-content {
            background: linear-gradient(135deg, rgba(20, 20, 30, 0.95) 0%, rgba(30, 30, 40, 0.95) 100%);
            border-radius: 30px;
            padding: 40px;
            max-width: 600px;
            width: 100%;
            max-height: 80vh;
            overflow-y: auto;
            position: relative;
            border: 1px solid rgba(255, 255, 255, 0.1);
            box-shadow: 0 25px 50px rgba(0, 0, 0, 0.5);
        }

        .modal-header {
            display: flex;
            justify-content: space-between;
            align-items: center;
            margin-bottom: 30px;
        }

        .modal-title {
            font-size: 1.8em;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
        }

        .close-btn {
            width: 40px;
            height: 40px;
            border-radius: 50%;
            background: rgba(255, 255, 255, 0.1);
            border: none;
            color: #fff;
            font-size: 24px;
            cursor: pointer;
            transition: all 0.3s ease;
            display: flex;
            align-items: center;
            justify-content: center;
        }

        .close-btn:hover {
            background: rgba(255, 255, 255, 0.2);
            transform: rotate(90deg);
        }

        .modal-section {
            margin-bottom: 25px;
        }

        .modal-section h4 {
            color: #ff6b6b;
            margin-bottom: 10px;
            display: flex;
            align-items: center;
            gap: 8px;
        }

        .problem-list {
            list-style: none;
            padding-left: 20px;
        }

        .problem-list li {
            color: #aaa;
            margin-bottom: 8px;
            position: relative;
            padding-left: 20px;
            line-height: 1.5;
        }

        .problem-list li::before {
            content: '‚Üí';
            position: absolute;
            left: 0;
            color: #ff6b6b;
        }

        .evolution-box {
            background: rgba(102, 126, 234, 0.1);
            border: 1px solid rgba(102, 126, 234, 0.3);
            border-radius: 15px;
            padding: 20px;
            margin-top: 20px;
        }

        .evolution-box h4 {
            color: #667eea;
            margin-bottom: 10px;
        }

        /* Custom scrollbar */
        ::-webkit-scrollbar {
            height: 8px;
            width: 8px;
        }

        ::-webkit-scrollbar-track {
            background: rgba(255, 255, 255, 0.05);
        }

        ::-webkit-scrollbar-thumb {
            background: rgba(102, 126, 234, 0.5);
            border-radius: 4px;
        }

        ::-webkit-scrollbar-thumb:hover {
            background: rgba(102, 126, 234, 0.7);
        }

        /* Responsive adjustments */
        @media (max-width: 768px) {
            .header {
                padding: 15px 20px;
            }
            
            .header-content {
                flex-direction: column;
                gap: 15px;
            }
            
            .title-section h1 {
                font-size: 1.5em;
            }
            
            .progress-section {
                width: 100%;
                justify-content: center;
            }
            
            .topics-view {
                flex-direction: column;
                gap: 40px;
            }
            
            .topic-circle {
                width: 150px;
                height: 150px;
            }
            
            .method-node {
                min-width: 250px;
            }
        }
    </style>
</head>
<body>
    <div class="header">
        <div class="header-content">
            <div class="title-section">
                <h1>NLP Learning Journey</h1>
                <p class="subtitle">by <span class="author">Eng. Omer Nacar</span></p>
            </div>
            <div class="progress-section">
                <div class="progress-bar">
                    <div class="progress-fill"></div>
                </div>
                <div class="progress-text">0 / 0 explored</div>
            </div>
        </div>
    </div>

    <div class="main-container">
        <!-- Home View -->
        <div class="home-view" id="homeView">
            <div class="nlp-main-node" onclick="showTopics()">
                <h2>NLP</h2>
            </div>
        </div>

        <!-- Topics View -->
        <div class="topics-view" id="topicsView">
            <div style="position: absolute; top: 40px; left: 40px; z-index: 100;">
                <button class="back-button" onclick="backToHome()" type="button">
                    ‚Üê
                </button>
            </div>
            <div class="topic-circle" onclick="showRoadmap(0)">
                <h3>Tokenization</h3>
            </div>
            <div class="topic-circle" onclick="showRoadmap(1)">
                <h3>Embeddings</h3>
            </div>
            <div class="topic-circle" onclick="showRoadmap(2)">
                <h3>Language<br>Modeling</h3>
            </div>
        </div>

        <!-- Roadmap View -->
        <div class="roadmap-view" id="roadmapView">
            <div class="roadmap-header">
                <div class="back-button" onclick="backToTopics()">‚Üê</div>
                <h2 class="roadmap-title" id="roadmapTitle"></h2>
            </div>
            <div class="methods-container" id="methodsContainer"></div>
        </div>
    </div>

    <div class="modal" id="modal">
        <div class="modal-content">
            <div class="modal-header">
                <h3 class="modal-title" id="modal-title"></h3>
                <button class="close-btn" onclick="closeModal()">√ó</button>
            </div>
            <div id="modal-body"></div>
        </div>
    </div>

    <script>
        const roadmapData = {
            "roadmap": [
                {
                    "topic": "Tokenization",
                    "methods": [
                        {
                            "title": "Whitespace Tokenization",
                            "description": "Splits text based on spaces.",
                            "problems": [
                                "Fails on punctuation and contractions",
                                "Can't handle compound words or named entities"
                            ],
                            "leads_to": "Rule-based Tokenization"
                        },
                        {
                            "title": "Rule-based Tokenization",
                            "description": "Uses regular expressions and linguistic rules.",
                            "problems": [
                                "Language-specific and brittle",
                                "Fails on unseen language constructs"
                            ],
                            "leads_to": "Statistical Tokenization"
                        },
                        {
                            "title": "Statistical Tokenization",
                            "description": "Uses frequency-based models to determine token boundaries.",
                            "problems": [
                                "Requires labeled data",
                                "Error-prone with rare or ambiguous tokens"
                            ],
                            "leads_to": "Character-level Tokenization"
                        },
                        {
                            "title": "Character-level Tokenization",
                            "description": "Splits text into characters, useful for noisy input and morphologically rich languages.",
                            "problems": [
                                "Loss of higher-level semantic units",
                                "Increased sequence length"
                            ],
                            "leads_to": "Subword Tokenization"
                        },
                        {
                            "title": "Subword Tokenization (BPE, WordPiece)",
                            "description": "Breaks words into subword units to manage rare or compound words.",
                            "problems": [
                                "Fragmented representations",
                                "Reduced interpretability"
                            ],
                            "leads_to": "Byte-level Tokenization"
                        },
                        {
                            "title": "Byte-level Tokenization",
                            "description": "Splits text into byte units, used in GPT-2/3 to avoid token vocabulary limits.",
                            "problems": [
                                "Further loss of linguistic structure",
                                "Harder for humans to interpret"
                            ],
                            "leads_to": "Unsupervised Tokenization"
                        },
                        {
                            "title": "Unsupervised Tokenization (e.g., SentencePiece)",
                            "description": "Learns tokens from raw text without pre-tokenization.",
                            "problems": [
                                "Opaque token formation",
                                "Can split in non-intuitive ways"
                            ],
                            "leads_to": "Embeddings"
                        }
                    ]
                },
                {
                    "topic": "Embeddings",
                    "methods": [
                        {
                            "title": "One-Hot Encoding",
                            "description": "Sparse binary representation for words.",
                            "problems": [
                                "No similarity between vectors",
                                "Very memory inefficient"
                            ],
                            "leads_to": "Co-occurrence Matrix"
                        },
                        {
                            "title": "Co-occurrence Matrix",
                            "description": "Counts how often words appear together.",
                            "problems": [
                                "Very high-dimensional",
                                "Lacks contextual understanding"
                            ],
                            "leads_to": "TF-IDF"
                        },
                        {
                            "title": "TF-IDF",
                            "description": "Weights word frequency by document relevance.",
                            "problems": [
                                "Still sparse",
                                "Ignores semantics"
                            ],
                            "leads_to": "Word2Vec"
                        },
                        {
                            "title": "Word2Vec (CBOW, Skip-Gram)",
                            "description": "Predicts words or contexts to learn embeddings.",
                            "problems": [
                                "Same vector for every occurrence of a word",
                                "Fails on polysemy"
                            ],
                            "leads_to": "GloVe"
                        },
                        {
                            "title": "GloVe",
                            "description": "Learns word embeddings from co-occurrence statistics.",
                            "problems": [
                                "No dynamic context awareness",
                                "Same vector for all contexts"
                            ],
                            "leads_to": "fastText"
                        },
                        {
                            "title": "fastText",
                            "description": "Embeds words using subword (n-gram) information.",
                            "problems": [
                                "Still lacks full context modeling",
                                "Not dynamic per sentence"
                            ],
                            "leads_to": "Char-level Embeddings"
                        },
                        {
                            "title": "Char-level Embeddings",
                            "description": "Creates embeddings from characters using CNNs or RNNs.",
                            "problems": [
                                "Higher complexity",
                                "May lack semantic abstraction"
                            ],
                            "leads_to": "Contextual Embeddings"
                        },
                        {
                            "title": "ELMo",
                            "description": "Contextual embeddings using bidirectional LSTMs.",
                            "problems": [
                                "Slow and memory intensive",
                                "Replaced by Transformer-based models"
                            ],
                            "leads_to": "BERT"
                        },
                        {
                            "title": "BERT",
                            "description": "Deep bidirectional Transformer using masked language modeling.",
                            "problems": [
                                "No generation capability",
                                "Resource-intensive"
                            ],
                            "leads_to": "GPT"
                        },
                        {
                            "title": "GPT",
                            "description": "Autoregressive Transformer for generation.",
                            "problems": [
                                "Unidirectional (no look-back)",
                                "Can generate inaccurate content"
                            ],
                            "leads_to": "T5"
                        },
                        {
                            "title": "T5",
                            "description": "Unified text-to-text transformer model.",
                            "problems": [
                                "Very large and expensive to train",
                                "May need task-specific tuning"
                            ],
                            "leads_to": "Multilingual & Instruction-tuned Embeddings"
                        },
                        {
                            "title": "Multilingual Embeddings (e.g., mBERT, XLM-R)",
                            "description": "Cross-lingual shared embedding space.",
                            "problems": [
                                "Loss of language-specific nuance",
                                "Alignment quality varies"
                            ],
                            "leads_to": "Language Modeling"
                        }
                    ]
                },
                {
                    "topic": "Language Modeling",
                    "methods": [
                        {
                            "title": "n-gram Models",
                            "description": "Predicts next word from previous n-1 words.",
                            "problems": [
                                "Context window is fixed and short",
                                "Data sparsity"
                            ],
                            "leads_to": "HMM"
                        },
                        {
                            "title": "Hidden Markov Models (HMM)",
                            "description": "Probabilistic state model for sequential data.",
                            "problems": [
                                "Assumes independence",
                                "Limited to short memory"
                            ],
                            "leads_to": "CRF"
                        },
                        {
                            "title": "Conditional Random Fields (CRF)",
                            "description": "Discriminative model for sequence labeling.",
                            "problems": [
                                "Feature engineering required",
                                "Fails on complex dependencies"
                            ],
                            "leads_to": "RNN"
                        },
                        {
                            "title": "Recurrent Neural Network (RNN)",
                            "description": "Models sequences by maintaining a hidden state.",
                            "problems": [
                                "Vanishing gradients",
                                "Hard to learn long dependencies"
                            ],
                            "leads_to": "LSTM"
                        },
                        {
                            "title": "LSTM",
                            "description": "Improves RNN with memory cells and gates.",
                            "problems": [
                                "Sequential ‚Äî slow to train",
                                "Still struggles on very long sequences"
                            ],
                            "leads_to": "GRU"
                        },
                        {
                            "title": "GRU",
                            "description": "Simpler alternative to LSTM with similar performance.",
                            "problems": [
                                "May underperform on complex tasks",
                                "Still sequential"
                            ],
                            "leads_to": "Bidirectional RNN"
                        },
                        {
                            "title": "Bidirectional RNN/LSTM",
                            "description": "Processes sequences in both directions.",
                            "problems": [
                                "Not usable in online generation",
                                "Doubles compute and memory"
                            ],
                            "leads_to": "Seq2Seq"
                        },
                        {
                            "title": "Seq2Seq (Encoder-Decoder)",
                            "description": "Maps input sequence to output with encoder-decoder model.",
                            "problems": [
                                "Information bottleneck in encoder",
                                "Fails on long input sequences"
                            ],
                            "leads_to": "Attention Mechanism"
                        },
                        {
                            "title": "Attention Mechanism",
                            "description": "Allows decoder to attend to all encoder states dynamically.",
                            "problems": [
                                "Sequential still limits parallelism",
                                "Not efficient for very long inputs"
                            ],
                            "leads_to": "Transformer"
                        },
                        {
                            "title": "Transformer",
                            "description": "Replaces recurrence with full self-attention; highly parallelizable.",
                            "problems": [
                                "Quadratic time/memory with input size",
                                "Data and compute heavy"
                            ],
                            "leads_to": "Efficient Transformers"
                        },
                        {
                            "title": "Efficient Transformers (e.g., Longformer, Reformer)",
                            "description": "Reduces transformer memory/compute using sparse attention.",
                            "problems": [
                                "Complex implementation",
                                "Still maturing in research"
                            ],
                            "leads_to": "Future of NLP"
                        }
                    ]
                }
            ]
        };

        let visitedMethods = new Set();
        let totalMethods = 0;
        let currentTopic = null;

        // Count total methods
        roadmapData.roadmap.forEach(topic => {
            totalMethods += topic.methods.length;
        });

        function showTopics() {
            document.getElementById('homeView').classList.add('hidden');
            document.getElementById('topicsView').classList.add('active');
        }

        function backToHome() {
            document.getElementById('topicsView').classList.remove('active');
            document.getElementById('homeView').classList.remove('hidden');
        }

        function showRoadmap(topicIndex) {
            currentTopic = topicIndex;
            const topic = roadmapData.roadmap[topicIndex];
            
            document.getElementById('topicsView').classList.remove('active');
            document.getElementById('roadmapView').classList.add('active');
            document.getElementById('roadmapTitle').textContent = topic.topic;
            
            // Clear and populate methods
            const container = document.getElementById('methodsContainer');
            container.innerHTML = '';
            
            topic.methods.forEach((method, methodIndex) => {
                // Add method node
                const node = document.createElement('div');
                node.className = 'method-node';
                node.dataset.topic = topicIndex;
                node.dataset.method = methodIndex;
                node.style.animationDelay = `${methodIndex * 0.1}s`;
                
                // Check if visited
                const key = `${topicIndex}-${methodIndex}`;
                if (visitedMethods.has(key)) {
                    node.classList.add('visited');
                }
                
                node.innerHTML = `
                    <div class="method-title">${method.title}</div>
                    <div class="method-desc">${method.description}</div>
                    <div class="method-problems">
                        <span>‚ö†Ô∏è</span>
                        <span>View problems</span>
                    </div>
                `;
                
                node.onclick = () => {
                    visitMethod(topicIndex, methodIndex);
                    showMethodDetails(method);
                };
                
                container.appendChild(node);
                
                // Add arrow between methods
                if (methodIndex < topic.methods.length - 1) {
                    const arrow = document.createElement('div');
                    arrow.className = 'arrow-connector';
                    arrow.innerHTML = '‚Üí';
                    container.appendChild(arrow);
                }
            });
        }

        function backToTopics() {
            document.getElementById('roadmapView').classList.remove('active');
            document.getElementById('topicsView').classList.add('active');
        }

        function visitMethod(topicIndex, methodIndex) {
            const key = `${topicIndex}-${methodIndex}`;
            if (!visitedMethods.has(key)) {
                visitedMethods.add(key);
                const node = document.querySelector(`[data-topic="${topicIndex}"][data-method="${methodIndex}"]`);
                if (node) {
                    node.classList.add('visited');
                }
                updateProgress();
            }
        }

        function updateProgress() {
            const percentage = (visitedMethods.size / totalMethods) * 100;
            document.querySelector('.progress-fill').style.width = `${percentage}%`;
            document.querySelector('.progress-text').textContent = 
                `${visitedMethods.size} / ${totalMethods} explored`;
        }

        function showMethodDetails(method) {
            const modal = document.getElementById('modal');
            const modalTitle = document.getElementById('modal-title');
            const modalBody = document.getElementById('modal-body');
            
            modalTitle.textContent = method.title;
            
            modalBody.innerHTML = `
                <div class="modal-section">
                    <p style="font-size: 1.1em; color: #ccc; line-height: 1.6;">
                        ${method.description}
                    </p>
                </div>
                
                <div class="modal-section">
                    <h4><span>‚ö†Ô∏è</span> Common Problems & Limitations</h4>
                    <ul class="problem-list">
                        ${method.problems.map(p => `<li>${p}</li>`).join('')}
                    </ul>
                </div>
                
                <div class="evolution-box">
                    <h4>üöÄ Evolution Path</h4>
                    <p style="color: #ccc;">This limitation led researchers to develop:</p>
                    <p style="font-size: 1.2em; margin-top: 10px; color: #fff;">
                        <strong>${method.leads_to}</strong>
                    </p>
                </div>
            `;
            
            modal.style.display = 'flex';
        }

        function closeModal() {
            document.getElementById('modal').style.display = 'none';
        }

        // Close modal on outside click
        window.onclick = (event) => {
            const modal = document.getElementById('modal');
            if (event.target === modal) {
                closeModal();
            }
        };

        // Initialize progress
        updateProgress();
    </script>
</body>
</html>
